# FINAL PROFESSIONAL VERSION v21.0 - Scraper Fallback
name: Video Uploader v21.0 (Scraper Fallback)

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Video URL'
        required: true
      message_id:
        description: 'Discord Message ID'
        required: false

jobs:
  upload:
    runs-on: ubuntu-latest
    steps:
      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            /usr/local/bin/ffmpeg
          key: ${{ runner.os }}-deps-v2

      - name: Install Dependencies
        run: |
          if ! command -v ffmpeg &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y ffmpeg
          else
            echo "ffmpeg is already cached."
          fi
          pip install --upgrade git+https://github.com/yt-dlp/yt-dlp.git gallery-dl requests beautifulsoup4

      - name: Resolve Short Links
        id: resolve
        run: |
          URL="${{ github.event.inputs.url }}"
          if [[ "$URL" == *"pin.it"* ]]; then
            echo "Short pin.it URL detected. Resolving..."
            # Use curl to follow redirects and get the final URL
            FINAL_URL=$(curl -s -L -o /dev/null -w '%{url_effective}' "$URL")
            echo "Resolved URL: $FINAL_URL"
            echo "url=$FINAL_URL" >> $GITHUB_OUTPUT
          else
            echo "URL is not a short link. Using original."
            echo "url=$URL" >> $GITHUB_OUTPUT
          fi

      - name: Download Video (Advanced Hybrid Method)
        id: download
        run: |
          VIDEO_URL="${{ steps.resolve.outputs.url }}"
          FINAL_FILENAME="video.mp4"

          if [[ "$VIDEO_URL" == *"pinterest.com"* ]]; then
            echo "Pinterest URL detected. Trying advanced Python scraper..."
            
            if python3 - "$VIDEO_URL" "$FINAL_FILENAME" <<'EOF'
          import requests, sys, random
          from bs4 import BeautifulSoup

          url = sys.argv[1]
          filename = sys.argv[2]

          USER_AGENTS = [
              "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
              "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
              "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0",
              "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148"
          ]

          def try_pinterestdownloader(session, target_url):
              try:
                  print("Attempting download via pinterestdownloader.com...")
                  r = session.post("https://pinterestdownloader.com/download.php", data={"url": target_url}, timeout=10)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.text, "html.parser")
                  link = soup.find("a", class_="download-link")
                  if link and link.get("href"):
                      return link["href"]
              except Exception as e:
                  print(f"pinterestdownloader.com failed: {e}", file=sys.stderr)
              return None

          def try_expertstool(session, target_url):
              try:
                  print("Attempting download via experts-tool.com...")
                  r = session.post("https://experts-tool.com/pinterest-video-downloader/download", data={"url": target_url}, timeout=10)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.text, "html.parser")
                  link = soup.find("a", href=True, string="Download")
                  if link and "https://download.expert-h.com" in link["href"]:
                      return link["href"]
              except Exception as e:
                  print(f"experts-tool.com failed: {e}", file=sys.stderr)
              return None

          with requests.Session() as s:
              s.headers.update({"User-Agent": random.choice(USER_AGENTS)})
              
              video_url = try_pinterestdownloader(s, url)
              
              if not video_url:
                  video_url = try_expertstool(s, url)

              if video_url:
                  print(f"Found direct URL: {video_url}")
                  vr = s.get(video_url, stream=True)
                  vr.raise_for_status()
                  with open(filename, "wb") as f:
                      for chunk in vr.iter_content(chunk_size=8192):
                          f.write(chunk)
                  print("Download via scraper successful.")
                  sys.exit(0)
              else:
                  print("All scrapers failed.", file=sys.stderr)
                  sys.exit(1)
          EOF
          then
              echo "‚úÖ Python scraper succeeded."
            else
              echo "‚ö†Ô∏è Scraper method failed. Falling back to gallery-dl..."
              gallery-dl --verbose --no-check-certificate --download-archive archive.txt --directory . "$VIDEO_URL"
              DOWNLOADED_FILE=$(find . -maxdepth 1 -type f -name "*.mp4" -print -quit)
              if [ -n "$DOWNLOADED_FILE" ]; then
                  echo "Found downloaded file: $DOWNLOADED_FILE. Renaming to $FINAL_FILENAME"
                  mv "$DOWNLOADED_FILE" "$FINAL_FILENAME"
              else
                  echo "‚ùå gallery-dl fallback also failed to download a file."
                  exit 1
              fi
            fi
          else
            echo "Non-Pinterest URL. Using yt-dlp..."
            yt-dlp \
              --format "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best" \
              --merge-output-format mp4 \
              --output "$FINAL_FILENAME" \
              "$VIDEO_URL"
          fi
          
          if [ -s "$FINAL_FILENAME" ]; then
            FILESIZE=$(stat -c%s "$FINAL_FILENAME")
            echo "‚úÖ Download successful. File is '$FINAL_FILENAME' with size $FILESIZE bytes."
            echo "filepath=$FINAL_FILENAME" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Download failed or resulted in an empty file after all attempts."
            exit 1
          fi

      - name: Upload to Catbox
        id: catbox
        run: |
          FILE_PATH="${{ steps.download.outputs.filepath }}"
          UNIQUE_FILENAME="video-$(date +%s)-${RANDOM}.mp4"
          echo "Uploading $FILE_PATH as $UNIQUE_FILENAME to Catbox..."
          
          OUTPUT_LINK=$(curl -F "reqtype=fileupload" -F "fileToUpload=@$FILE_PATH;filename=$UNIQUE_FILENAME" https://catbox.moe/user/api.php)
          
          echo "Catbox API Response: '$OUTPUT_LINK'"
          if [[ -n "$OUTPUT_LINK" && "$OUTPUT_LINK" =~ ^https:// ]]; then
            echo "‚úÖ Upload successful: $OUTPUT_LINK"
            echo "link=$OUTPUT_LINK" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Upload Failed. Response was empty or not a URL."
            exit 1
          fi

      - name: Send Result to Discord
        if: success()
        run: |
          MESSAGE_ID="${{ github.event.inputs.message_id }}"
          if [ -n "$MESSAGE_ID" ]; then
            curl -s -X POST -H "Content-Type: application/json" \
            -d '{"content": "üîó Result for message '"$MESSAGE_ID"': ${{ steps.catbox.outputs.link }}"}' \
            "${{ secrets.DISCORD_RESULTS_WEBHOOK }}"
          fi
      
      - name: Notify on Failure
        if: failure()
        run: |
          MESSAGE_ID="${{ github.event.inputs.message_id }}"
          if [ -n "$MESSAGE_ID" ]; then
            curl -s -X POST -H "Content-Type: application/json" \
            -d '{"content": "‚ùå Failed to process URL for message '"$MESSAGE_ID"': ${{ github.event.inputs.url }}"}' \
            "${{ secrets.DISCORD_RESULTS_WEBHOOK }}"
          fi
